{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data \n",
      "    id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "Test data \n",
      "    id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
      "Length of Training data \n",
      " 7613\n",
      "Length of Test data \n",
      " 3263\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv', names=['id','keyword', 'location', 'text', 'target'], skiprows = 1)\n",
    "test_data = pd.read_csv('test.csv', names=['id','keyword', 'location', 'text'], skiprows = 1)\n",
    "print(\"Training data \\n\",data.head())\n",
    "print(\"Test data \\n\",test_data.head())\n",
    "print(\"Length of Training data \\n\", len(data))\n",
    "print(\"Length of Test data \\n\", len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: target, dtype: int64\n",
      "0    Our Deeds are the Reason of this #earthquake M...\n",
      "1               Forest fire near La Ronge Sask. Canada\n",
      "2    All residents asked to 'shelter in place' are ...\n",
      "3    13,000 people receive #wildfires evacuation or...\n",
      "4    Just got sent this photo from Ruby #Alaska as ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_y = data['target']\n",
    "data_x = data['text']\n",
    "test = test_data['text']\n",
    "print(data_y.head())\n",
    "print(data_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "   (0, 3849)\t1\n",
      "  (0, 4918)\t1\n",
      "  (0, 8653)\t1\n",
      "  (0, 10427)\t1\n",
      "  (0, 18386)\t1\n",
      "  (1, 4302)\t1\n",
      "  (1, 5721)\t1\n",
      "  (1, 6311)\t1\n",
      "  (1, 8790)\t1\n",
      "  (1, 16324)\t1\n",
      "  (1, 17643)\t1\n",
      "  (2, 7436)\t1\n",
      "  (2, 7563)\t1\n",
      "  (2, 14575)\t1\n",
      "  (2, 16457)\t1\n",
      "  (2, 17492)\t1\n",
      "  (2, 17771)\t1\n",
      "  (3, 2091)\t1\n",
      "  (3, 11311)\t1\n",
      "  (3, 17477)\t1\n",
      "  (3, 20344)\t1\n",
      "  (4, 425)\t1\n",
      "  (4, 4203)\t1\n",
      "  (4, 10713)\t1\n",
      "  (4, 17354)\t1\n",
      "  :\t:\n",
      "  (3259, 11521)\t1\n",
      "  (3259, 14651)\t1\n",
      "  (3259, 15883)\t1\n",
      "  (3259, 17735)\t1\n",
      "  (3259, 20530)\t1\n",
      "  (3259, 20896)\t1\n",
      "  (3260, 4177)\t1\n",
      "  (3260, 5563)\t1\n",
      "  (3260, 8349)\t1\n",
      "  (3260, 9192)\t1\n",
      "  (3260, 11352)\t1\n",
      "  (3261, 658)\t1\n",
      "  (3261, 8738)\t1\n",
      "  (3261, 9192)\t1\n",
      "  (3261, 9283)\t1\n",
      "  (3261, 9950)\t1\n",
      "  (3261, 12107)\t1\n",
      "  (3261, 13851)\t1\n",
      "  (3261, 20192)\t1\n",
      "  (3262, 1547)\t1\n",
      "  (3262, 4309)\t1\n",
      "  (3262, 6538)\t1\n",
      "  (3262, 12727)\t1\n",
      "  (3262, 14444)\t1\n",
      "  (3262, 21089)\t1\n",
      "x_traincv: \n",
      "   (0, 5429)\t1\n",
      "  (0, 15499)\t1\n",
      "  (0, 6311)\t1\n",
      "  (0, 1844)\t1\n",
      "  (0, 7572)\t1\n",
      "  (1, 7563)\t1\n",
      "  (1, 12979)\t1\n",
      "  (1, 10967)\t1\n",
      "  (1, 16087)\t1\n",
      "  (1, 16431)\t1\n",
      "  (1, 3790)\t1\n",
      "  (2, 15761)\t1\n",
      "  (2, 2283)\t1\n",
      "  (2, 16835)\t2\n",
      "  (2, 14437)\t2\n",
      "  (2, 13270)\t1\n",
      "  (2, 13544)\t1\n",
      "  (2, 6835)\t1\n",
      "  (2, 13772)\t1\n",
      "  (2, 6933)\t1\n",
      "  (3, 6835)\t1\n",
      "  (3, 13772)\t1\n",
      "  (3, 176)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 14216)\t1\n",
      "  :\t:\n",
      "  (7610, 18)\t1\n",
      "  (7610, 21160)\t1\n",
      "  (7611, 3849)\t1\n",
      "  (7611, 14557)\t1\n",
      "  (7611, 11294)\t1\n",
      "  (7611, 15907)\t1\n",
      "  (7611, 11391)\t1\n",
      "  (7611, 9848)\t1\n",
      "  (7611, 18591)\t1\n",
      "  (7611, 13212)\t1\n",
      "  (7611, 3001)\t2\n",
      "  (7611, 4533)\t1\n",
      "  (7611, 14607)\t1\n",
      "  (7611, 17886)\t1\n",
      "  (7611, 9724)\t1\n",
      "  (7612, 3746)\t1\n",
      "  (7612, 9192)\t1\n",
      "  (7612, 13050)\t1\n",
      "  (7612, 11062)\t1\n",
      "  (7612, 13240)\t1\n",
      "  (7612, 1434)\t1\n",
      "  (7612, 20343)\t1\n",
      "  (7612, 9060)\t1\n",
      "  (7612, 15428)\t1\n",
      "  (7612, 20993)\t1\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df = 1 , stop_words = 'english')\n",
    "x_traincv = cv.fit_transform(data_x)\n",
    "y_train = data_y\n",
    "test = cv.transform(test)\n",
    "print(\"Test: \\n\", test)\n",
    "print(\"x_traincv: \\n\", x_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "fakenews rows\n",
      "[   1    2    3 ... 3261 3262 3263]\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_traincv,y_train)\n",
    "predictions = clf.predict(test)\n",
    "print(predictions)\n",
    "position_of_fakenews = np.where(predictions != 0)[0]\n",
    "for i in range(0 , len(position_of_fakenews)):\n",
    "    position_of_fakenews[i] += 1\n",
    "print('fakenews rows')\n",
    "print(position_of_fakenews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[   1    2    3 ... 1112 1113 1114]\n",
      "3263\n",
      "1114\n"
     ]
    }
   ],
   "source": [
    "pred = np.array(predictions)\n",
    "ids = np.arange(1114)\n",
    "for i in range(0,1114):\n",
    "    ids[i] += 1\n",
    "print(pred)\n",
    "print(ids)\n",
    "print(len(pred))\n",
    "print(len(ids))\n",
    "to_submit = pd.DataFrame({'target': pred})\n",
    "to_submit.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit.target = to_submit.target.astype(bool)\n",
    "to_submit = pd.DataFrame(to_submit)\n",
    "to_submit.target.to_csv('nlp.csv' , index_label = 'id', header = 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
