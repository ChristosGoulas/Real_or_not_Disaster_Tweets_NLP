{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading data\n",
    "\n",
    "data = pd.read_csv('train.csv', names=['id','keyword', 'location', 'text', 'target'], skiprows = 1)\n",
    "test_data = pd.read_csv('test.csv', names=['id','keyword', 'location', 'text'], skiprows = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data \n",
      "    id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "Test data \n",
      "    id keyword location                                               text\n",
      "0   0     NaN      NaN  Our Deeds are the Reason of this #earthquake M...\n",
      "1   2     NaN      NaN             Forest fire near La Ronge Sask. Canada\n",
      "2   3     NaN      NaN  All residents asked to 'shelter in place' are ...\n",
      "3   9     NaN      NaN  13,000 people receive #wildfires evacuation or...\n",
      "4  11     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...\n",
      "Length of Training data \n",
      " 7613\n",
      "Length of Test data \n",
      " 3263\n"
     ]
    }
   ],
   "source": [
    "#combining text from keyword, location and text \n",
    "\n",
    "columns = ['location', 'text']\n",
    "data['text'] = data[columns].astype(str).sum(axis=1)\n",
    "t_data_list = []\n",
    "\n",
    "for n in data['text']:\n",
    "    \n",
    "    row = str(n)\n",
    "    row = row.replace('nannan', '')\n",
    "    row = row.replace('nan', '')\n",
    "    t_data_list.append(row)\n",
    "\n",
    "data['text'] = t_data_list\n",
    "####################################################\n",
    "\n",
    "test_data['text'] = data[columns].astype(str).sum(axis=1)\n",
    "t_data_list = []\n",
    "\n",
    "for n in test_data['text']:\n",
    "    \n",
    "    row = str(n)\n",
    "    row = row.replace('nannan', '')\n",
    "    row = row.replace('nan', '')\n",
    "    t_data_list.append(row)\n",
    "\n",
    "test_data['text'] = t_data_list\n",
    "\n",
    "print(\"Training data \\n\",data.head())\n",
    "print(\"Test data \\n\",test_data.head())\n",
    "print(\"Length of Training data \\n\", len(data))\n",
    "print(\"Length of Test data \\n\", len(test_data))\n",
    "data.groupby('target').size() #0: fake 4342   1:real 3271\n",
    "data.to_csv('t.csv', header = 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: target, dtype: int64\n",
      "0    Our Deeds are the Reason of this #earthquake M...\n",
      "1               Forest fire near La Ronge Sask. Canada\n",
      "2    All residents asked to 'shelter in place' are ...\n",
      "3    13,000 people receive #wildfires evacuation or...\n",
      "4    Just got sent this photo from Ruby #Alaska as ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data_y = data['target']\n",
    "data_x = data['text']\n",
    "test = test_data['text']\n",
    "print(data_y.head())\n",
    "print(data_x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "   (0, 18473)\t0.395377275408484\n",
      "  (0, 8909)\t0.5104343743408171\n",
      "  (0, 7458)\t0.3580364205039489\n",
      "  (0, 6492)\t0.5104343743408171\n",
      "  (0, 2083)\t0.44090841528131525\n",
      "  (1, 19481)\t0.5003786477180231\n",
      "  (1, 19103)\t0.5233318167130359\n",
      "  (1, 15411)\t0.32985608580793785\n",
      "  (1, 12952)\t0.3681742877434479\n",
      "  (1, 8896)\t0.3289355861741757\n",
      "  (1, 4502)\t0.35098298416310514\n",
      "  (2, 19943)\t0.5556646105909391\n",
      "  (2, 18748)\t0.2725747407974012\n",
      "  (2, 17320)\t0.45564089712137795\n",
      "  (2, 16486)\t0.25419137155108457\n",
      "  (2, 16189)\t0.26802043127358316\n",
      "  (2, 15826)\t0.315302298762353\n",
      "  (2, 8183)\t0.2443794975291982\n",
      "  (2, 8060)\t0.2098771713285334\n",
      "  (2, 2627)\t0.2640032455729709\n",
      "  (3, 24174)\t0.38126894440386544\n",
      "  (3, 18494)\t0.4469700312435817\n",
      "  (3, 17053)\t0.23746335889266923\n",
      "  (3, 16486)\t0.37686902375111725\n",
      "  (3, 8060)\t0.31116793691140093\n",
      "  :\t:\n",
      "  (3260, 11447)\t0.3644819106813736\n",
      "  (3260, 9325)\t0.3644819106813736\n",
      "  (3260, 7849)\t0.24944448077659792\n",
      "  (3260, 7160)\t0.2938391415011162\n",
      "  (3261, 23833)\t0.22253659430525854\n",
      "  (3261, 22571)\t0.2907387189259629\n",
      "  (3261, 22424)\t0.31245361985048203\n",
      "  (3261, 17808)\t0.3270498292576976\n",
      "  (3261, 16998)\t0.2703185024885713\n",
      "  (3261, 13916)\t0.3270498292576976\n",
      "  (3261, 13022)\t0.5200679233268607\n",
      "  (3261, 11709)\t0.27495625249231026\n",
      "  (3261, 7849)\t0.25891271339076977\n",
      "  (3261, 4473)\t0.2611867985149627\n",
      "  (3262, 24358)\t0.25096388612786225\n",
      "  (3262, 21135)\t0.353105281390259\n",
      "  (3262, 19625)\t0.24165853227450412\n",
      "  (3262, 18939)\t0.326629931876771\n",
      "  (3262, 17207)\t0.31810677304641677\n",
      "  (3262, 16754)\t0.353105281390259\n",
      "  (3262, 13369)\t0.15784853476959332\n",
      "  (3262, 13343)\t0.353105281390259\n",
      "  (3262, 7849)\t0.24165853227450412\n",
      "  (3262, 6440)\t0.326629931876771\n",
      "  (3262, 2368)\t0.326629931876771\n",
      "x_traincv: \n",
      "   (0, 8909)\t0.5104343743408171\n",
      "  (0, 2083)\t0.44090841528131525\n",
      "  (0, 7458)\t0.3580364205039489\n",
      "  (0, 18473)\t0.395377275408484\n",
      "  (0, 6492)\t0.5104343743408171\n",
      "  (1, 4502)\t0.35098298416310514\n",
      "  (1, 19481)\t0.5003786477180231\n",
      "  (1, 19103)\t0.5233318167130359\n",
      "  (1, 12952)\t0.3681742877434479\n",
      "  (1, 15411)\t0.32985608580793785\n",
      "  (1, 8896)\t0.3289355861741757\n",
      "  (2, 8183)\t0.2443794975291982\n",
      "  (2, 16486)\t0.25419137155108457\n",
      "  (2, 8060)\t0.2098771713285334\n",
      "  (2, 16189)\t0.26802043127358316\n",
      "  (2, 15826)\t0.315302298762353\n",
      "  (2, 17320)\t0.45564089712137795\n",
      "  (2, 19943)\t0.5556646105909391\n",
      "  (2, 2627)\t0.2640032455729709\n",
      "  (2, 18748)\t0.2725747407974012\n",
      "  (3, 4409)\t0.25086433485557097\n",
      "  (3, 24174)\t0.38126894440386544\n",
      "  (3, 18494)\t0.4469700312435817\n",
      "  (3, 17053)\t0.23746335889266923\n",
      "  (3, 1)\t0.41191952749734956\n",
      "  :\t:\n",
      "  (7610, 23)\t0.3241368122717673\n",
      "  (7610, 10801)\t0.07619040405900487\n",
      "  (7611, 11461)\t0.21073766551060524\n",
      "  (7611, 21137)\t0.2928571735289387\n",
      "  (7611, 17522)\t0.2928571735289387\n",
      "  (7611, 5470)\t0.21152497592720554\n",
      "  (7611, 3520)\t0.5704305781132881\n",
      "  (7611, 15752)\t0.24759166901295643\n",
      "  (7611, 21960)\t0.26911931220630875\n",
      "  (7611, 11605)\t0.24538145088367877\n",
      "  (7611, 13445)\t0.20568165004350744\n",
      "  (7611, 18905)\t0.27897141480788107\n",
      "  (7611, 13339)\t0.1851072511494624\n",
      "  (7611, 17456)\t0.17581201439155725\n",
      "  (7611, 4621)\t0.1862301876466389\n",
      "  (7612, 24920)\t0.49107181539881495\n",
      "  (7612, 18401)\t0.3421576650310943\n",
      "  (7612, 10647)\t0.3104006388448568\n",
      "  (7612, 24173)\t0.3014586881224599\n",
      "  (7612, 1607)\t0.35482202857008743\n",
      "  (7612, 15786)\t0.29998304117575764\n",
      "  (7612, 13080)\t0.3131253321826479\n",
      "  (7612, 15513)\t0.25001587543123505\n",
      "  (7612, 10801)\t0.0930573318809917\n",
      "  (7612, 4409)\t0.26352823672421555\n"
     ]
    }
   ],
   "source": [
    "cv = TfidfVectorizer(min_df = 1 , stop_words = 'english')\n",
    "x_traincv = cv.fit_transform(data_x)\n",
    "y_train = data_y\n",
    "test = cv.transform(test)\n",
    "print(\"Test: \\n\", test)\n",
    "print(\"x_traincv: \\n\", x_traincv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263\n",
      "[1 1 1 ... 1 0 0]\n",
      "fakenews rows\n",
      "[   5   12   13 ... 3260 3262 3263]\n",
      "2179\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_traincv, y_train)\n",
    "predictions = clf.predict(test)\n",
    "print(len(predictions))\n",
    "print(predictions)\n",
    "position_of_fakenews = np.where(predictions == 0)[0]\n",
    "for i in range(0 , len(position_of_fakenews)):\n",
    "    position_of_fakenews[i] += 1\n",
    "print('fakenews rows')\n",
    "print(position_of_fakenews)\n",
    "print(len(position_of_fakenews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 0 0]\n",
      "3263\n",
      "       target\n",
      "id           \n",
      "0           1\n",
      "2           1\n",
      "3           1\n",
      "9           1\n",
      "11          0\n",
      "...       ...\n",
      "10861       0\n",
      "10865       0\n",
      "10868       1\n",
      "10874       0\n",
      "10875       0\n",
      "\n",
      "[3263 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "pred = np.array(predictions)\n",
    "\n",
    "ids = list(test_data['id'])\n",
    "print(pred)\n",
    "print(len(pred))\n",
    "to_submit = pd.DataFrame({'id': ids, 'target': pred})\n",
    "to_submit.set_index('id', inplace = True)\n",
    "print(to_submit)\n",
    "#to_submit.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit.target = to_submit#.target.astype(bool)\n",
    "to_submit = pd.DataFrame(to_submit)\n",
    "to_submit.target.to_csv('nlp_locationtext.csv', header = 'False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
